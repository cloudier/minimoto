#!/usr/bin/python3

"""
The transcoding service layer is a pool of AWS EC2 instances, which we call
service instances. Each service instance is launched from the same Amazon
Machine Image (AMI), which you will have created as part of setup and which
contains the image-to-video transcoding code you will have implemented.

A transcoding process is launched by cron and must do the following.

- If the instance is still processing the previous request, do nothing and exit.
- Pull a request from an SQS queue. If no request is found, do nothing and exit.
- Download all images from the S3 bucket specified in the request (e.g.,
au.edu.unsw.cs9243.input/sample_images_xyz).
- Convert a series of images to an MP4 video using avconv (it is up to you how
you order the images, but ordering based on filename would be sufficient).
- Upload the MP4 video to the S3 bucket specified in the request
(e.g., au.edu.unsw.cs9243.output).
- It is important to limit the number of requests processed on a machine at one
time. Media transcoding is a CPU intensive task and processing multiple requests
on one machine poses a risk of a machine crash. This is why we start the jobs
via cron and make sure that only one is running at a time. Also, parallelisation
does not bring much benefit unless a machine has many CPUs or cores. Note that
if the service instance has more than one core, you may start multiple requests
so that all cores are utilised, however this is optional and not a requirement
of the assignment.

Using a work queue to let instances control the degree of parallelisation is a
common architecture pattern. It is possible to “push” requests to instances but
there must be a mechanism to avoid pushing too many requests to an instance.

The transcoding processes should also log their progress to a log file
(called minimoto.log) in the home directory of the service instance.
The specific log file format is up to you, but it should contain information
about each run of the transcoding process and provide details such as the
success or failure of the run, any arguments received, and any other interesting
output that could help diagnose and fix problems. Note that there should be one
log file per service instance. All transcoding processes running on the same
service instance must write (append) to the same log file.
"""

import os
import boto3
import shutil
import subprocess

from minimoto_constants import *

RUNNING_FILE_NAME = "MINIMOTO_SERVICE_RUNNING"
LOCAL_IMAGES_DIR = "images_dir"
LOCAL_VIDEO_FILE = "video_file.mp4"

def main():
    # Log to minimoto.log
    print("minimoto service starting")

    # If the instance is still processing the previous request, do nothing and
    # exit.
    if os.path.exists(RUNNING_FILE_NAME):
        print("minimoto service still running, exiting")
        return

    running_file = open(RUNNING_FILE_NAME, "w+")
    running_file.close()

    # Pull a request from an SQS queue. If no request is found, do nothing and
    # exit.
    print("Trying to get a request from queue")
    s3 = boto3.resource("s3", region_name="ap-southeast-2")
    sqs = boto3.resource("sqs", region_name="ap-southeast-2")
    queue = sqs.get_queue_by_name(QueueName=TRANSCODING_REQUESTS_QUEUE_NAME)
    messages = queue.receive_messages()

    if len(messages) == 0:
        print("No messages in queue, exiting")
        os.remove(RUNNING_FILE_NAME)
        return

    message = messages[0]
    s3_dirname = message.body

    print("Processing message to create %s.mp4" % s3_dirname)

    # Download all images from the S3 bucket specified in the request
    # (e.g., au.edu.unsw.cs9243.input/sample_images_xyz).
    subprocess.run(["aws", "--region", "ap-southeast-2", "s3", "sync",
                    "s3://%s/%s" % (INPUT_BUCKET_NAME, s3_dirname),
                    LOCAL_IMAGES_DIR])

    # Convert a series of images to an MP4 video using avconv (it is up to you
    # how you order the images, but ordering based on filename would be
    # sufficient).
    try:
        subprocess.check_call(["./img2video", LOCAL_IMAGES_DIR,
                               LOCAL_VIDEO_FILE])
    except Exception as e:
        print("img2video failed")
        shutil.rmtree(LOCAL_IMAGES_DIR)
        os.remove(LOCAL_VIDEO_FILE)
        os.remove(RUNNING_FILE_NAME)
        return

    # Upload the MP4 video to the S3 bucket specified in the request
    # (e.g., au.edu.unsw.cs9243.output).
    output_bucket = s3.Bucket(OUTPUT_BUCKET_NAME)
    output_bucket.upload_file(LOCAL_VIDEO_FILE, s3_dirname + ".mp4")

    # delete images from input bucket
    subprocess.run(["aws", "--region", "ap-southeast-2", "s3", "rm",
                    "s3://%s/%s" % (INPUT_BUCKET_NAME, s3_dirname),
                    "--recursive"])

    # Delete processed message from queue
    message.delete()

    shutil.rmtree(LOCAL_IMAGES_DIR)
    os.remove(LOCAL_VIDEO_FILE)
    os.remove(RUNNING_FILE_NAME)


if __name__ == "__main__":
    try:
        main()
    except Exception:
        os.remove(RUNNING_FILE_NAME)
